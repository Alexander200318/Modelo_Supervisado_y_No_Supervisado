import streamlit as st
import pandas as pd
import numpy as np
import pickle
import json
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.ensemble import AdaBoostClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.cluster import AgglomerativeClustering
from sklearn.metrics import silhouette_score, davies_bouldin_score
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.cluster.hierarchy import dendrogram, linkage

# Configuraci√≥n de la p√°gina
st.set_page_config(
    page_title="ML App - AdaBoost & Hierarchical Clustering",
    page_icon="ü§ñ",
    layout="wide"
)

# T√≠tulo principal
st.title("ü§ñ Aplicaci√≥n de Machine Learning")
st.markdown("**AdaBoost** (Supervisado) y **Clustering Jer√°rquico** (No Supervisado)")
st.divider()

# Cargar datos
@st.cache_data
def load_data():
    iris = load_iris()
    X = iris.data
    y = iris.target
    feature_names = iris.feature_names
    target_names = iris.target_names
    df = pd.DataFrame(X, columns=feature_names)
    df['target'] = y
    df['target_name'] = [target_names[i] for i in y]
    return X, y, feature_names, target_names, df

X, y, feature_names, target_names, df = load_data()

# Sidebar para selecci√≥n de modo
st.sidebar.title("‚öôÔ∏è Configuraci√≥n")
mode = st.sidebar.radio(
    "Seleccione el modo:",
    ["üè† Inicio", "üìä Modo Supervisado (AdaBoost)", "üîç Modo No Supervisado (Clustering)", "üíæ Zona de Exportaci√≥n"]
)

# ==================== P√ÅGINA DE INICIO ====================
if mode == "üè† Inicio":
    st.header("Bienvenido a la Aplicaci√≥n de Machine Learning")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üìä Modelo Supervisado")
        st.markdown("""
        **AdaBoost Classifier**
        - Algoritmo de ensemble boosting
        - Combina m√∫ltiples clasificadores d√©biles
        - Ideal para clasificaci√≥n multiclase
        """)
        
    with col2:
        st.subheader("üîç Modelo No Supervisado")
        st.markdown("""
        **Clustering Jer√°rquico (Average Linkage)**
        - Agrupa datos sin etiquetas
        - Construye jerarqu√≠a de clusters
        - M√©todo: Average Linkage
        """)
    
    st.divider()
    
    st.subheader("üìÅ Dataset: Iris")
    st.write(f"**Dimensiones**: {X.shape[0]} muestras, {X.shape[1]} caracter√≠sticas")
    st.write(f"**Clases**: {', '.join(target_names)}")
    
    st.dataframe(df.head(10), use_container_width=True)
    
    st.markdown("""
    ### üìå Instrucciones:
    1. Use el men√∫ lateral para navegar entre modos
    2. **Modo Supervisado**: Entrene AdaBoost y haga predicciones
    3. **Modo No Supervisado**: Aplique clustering jer√°rquico
    4. **Zona de Exportaci√≥n**: Descargue modelos y resultados en JSON
    """)

# ==================== MODO SUPERVISADO ====================
elif mode == "üìä Modo Supervisado (AdaBoost)":
    st.header("üìä Modelo Supervisado: AdaBoost Classifier")
    
    # Par√°metros del modelo
    st.sidebar.subheader("Par√°metros del Modelo")
    n_estimators = st.sidebar.slider("N√∫mero de estimadores", 10, 200, 50, 10)
    learning_rate = st.sidebar.slider("Learning Rate", 0.1, 2.0, 1.0, 0.1)
    random_state = st.sidebar.number_input("Random State", 0, 100, 42)
    
    # Dividir datos
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=random_state
    )
    
    # Entrenar modelo
    if st.button("üöÄ Entrenar Modelo", type="primary"):
        with st.spinner("Entrenando modelo AdaBoost..."):
            # Crear y entrenar modelo
            base_estimator = DecisionTreeClassifier(max_depth=1)
            model = AdaBoostClassifier(
                estimator=base_estimator,
                n_estimators=n_estimators,
                learning_rate=learning_rate,
                random_state=random_state,
                algorithm='SAMME'
            )
            model.fit(X_train, y_train)
            
            # Predicciones
            y_pred = model.predict(X_test)
            
            # Calcular m√©tricas
            accuracy = accuracy_score(y_test, y_pred)
            precision = precision_score(y_test, y_pred, average='weighted')
            recall = recall_score(y_test, y_pred, average='weighted')
            f1 = f1_score(y_test, y_pred, average='weighted')
            
            # Guardar en session_state
            st.session_state['supervised_model'] = model
            st.session_state['supervised_metrics'] = {
                'accuracy': accuracy,
                'precision': precision,
                'recall': recall,
                'f1_score': f1
            }
            
        st.success("‚úÖ Modelo entrenado exitosamente!")
    
    # Mostrar m√©tricas si el modelo existe
    if 'supervised_model' in st.session_state:
        st.subheader("üìà M√©tricas de Evaluaci√≥n")
        
        col1, col2, col3, col4 = st.columns(4)
        metrics = st.session_state['supervised_metrics']
        
        with col1:
            st.metric("Exactitud", f"{metrics['accuracy']:.4f}")
        with col2:
            st.metric("Precisi√≥n", f"{metrics['precision']:.4f}")
        with col3:
            st.metric("Recordar", f"{metrics['recall']:.4f}")
        with col4:
            st.metric("F1-Score", f"{metrics['f1_score']:.4f}")
        
        st.divider()
        
        # Secci√≥n de predicci√≥n interactiva
        st.subheader("üéØ Predicci√≥n Interactiva")
        st.markdown("Ajuste los valores de las caracter√≠sticas para obtener una predicci√≥n:")
        
        col1, col2 = st.columns(2)
        
        with col1:
            sepal_length = st.slider(
                "Largo del s√©palo (cm)",
                float(X[:, 0].min()),
                float(X[:, 0].max()),
                float(X[:, 0].mean())
            )
            sepal_width = st.slider(
                "Ancho del s√©palo (cm)",
                float(X[:, 1].min()),
                float(X[:, 1].max()),
                float(X[:, 1].mean())
            )
        
        with col2:
            petal_length = st.slider(
                "Largo del p√©talo (cm)",
                float(X[:, 2].min()),
                float(X[:, 2].max()),
                float(X[:, 2].mean())
            )
            petal_width = st.slider(
                "Ancho del p√©talo (cm)",
                float(X[:, 3].min()),
                float(X[:, 3].max()),
                float(X[:, 3].mean())
            )
        
        # Realizar predicci√≥n
        input_data = np.array([[sepal_length, sepal_width, petal_length, petal_width]])
        prediction = st.session_state['supervised_model'].predict(input_data)[0]
        prediction_proba = st.session_state['supervised_model'].predict_proba(input_data)[0]
        
        st.divider()
        
        col1, col2 = st.columns([1, 2])
        
        with col1:
            st.markdown("### üéØ Resultado")
            st.success(f"**Clase Predicha**: {prediction}")
            st.info(f"**Nombre**: {target_names[prediction]}")
        
        with col2:
            st.markdown("### üìä Probabilidades")
            proba_df = pd.DataFrame({
                'Clase': target_names,
                'Probabilidad': prediction_proba
            })
            st.dataframe(proba_df, use_container_width=True)
        
        # Guardar predicci√≥n actual
        st.session_state['current_prediction'] = {
            'input': input_data[0].tolist(),
            'output_class': int(prediction),
            'output_label': target_names[prediction],
            'probabilities': prediction_proba.tolist()
        }

# ==================== MODO NO SUPERVISADO ====================
elif mode == "üîç Modo No Supervisado (Clustering)":
    st.header("üîç Clustering Jer√°rquico (Average Linkage)")
    
    # Par√°metros del modelo
    st.sidebar.subheader("Par√°metros del Clustering")
    n_clusters = st.sidebar.slider("N√∫mero de Clusters", 2, 6, 3)
    
    # Normalizar datos
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    if st.button("üöÄ Aplicar Clustering", type="primary"):
        with st.spinner("Aplicando clustering jer√°rquico..."):
            # Crear y aplicar modelo
            model = AgglomerativeClustering(
                n_clusters=n_clusters,
                linkage='average'
            )
            cluster_labels = model.fit_predict(X_scaled)
            
            # Calcular m√©tricas
            silhouette = silhouette_score(X_scaled, cluster_labels)
            davies_bouldin = davies_bouldin_score(X_scaled, cluster_labels)
            
            # Guardar en session_state
            st.session_state['unsupervised_model'] = model
            st.session_state['cluster_labels'] = cluster_labels
            st.session_state['unsupervised_metrics'] = {
                'silhouette_score': silhouette,
                'davies_bouldin': davies_bouldin
            }
            st.session_state['n_clusters'] = n_clusters
            
        st.success("‚úÖ Clustering aplicado exitosamente!")
    
    # Mostrar resultados si el modelo existe
    if 'unsupervised_model' in st.session_state:
        st.subheader("üìà M√©tricas de Calidad")
        
        col1, col2 = st.columns(2)
        metrics = st.session_state['unsupervised_metrics']
        
        with col1:
            st.metric(
                "Silhouette Score",
                f"{metrics['silhouette_score']:.4f}",
                help="Valores cercanos a 1 indican mejor separaci√≥n"
            )
        with col2:
            st.metric(
                "Davies-Bouldin Score",
                f"{metrics['davies_bouldin']:.4f}",
                help="Valores m√°s bajos indican mejor clustering"
            )
        
        st.divider()
        
        # Visualizaci√≥n de clusters
        st.subheader("üìä Visualizaci√≥n de Clusters")
        
        cluster_labels = st.session_state['cluster_labels']
        
        # Crear visualizaci√≥n 2D
        fig, axes = plt.subplots(1, 2, figsize=(14, 5))
        
        # Plot 1: Sepal
        scatter1 = axes[0].scatter(
            X[:, 0], X[:, 1],
            c=cluster_labels,
            cmap='viridis',
            s=100,
            alpha=0.6,
            edgecolors='black'
        )
        axes[0].set_xlabel('Largo del s√©palo (cm)')
        axes[0].set_ylabel('Ancho del s√©palo (cm)')
        axes[0].set_title('Clusters - Caracter√≠sticas Sepal')
        plt.colorbar(scatter1, ax=axes[0])
        
        # Plot 2: Petal
        scatter2 = axes[1].scatter(
            X[:, 2], X[:, 3],
            c=cluster_labels,
            cmap='viridis',
            s=100,
            alpha=0.6,
            edgecolors='black'
        )
        axes[1].set_xlabel('Largo del p√©talo (cm)')
        axes[1].set_ylabel('Ancho del p√©talo (cm)')
        axes[1].set_title('Clusters - Caracter√≠sticas Petal')
        plt.colorbar(scatter2, ax=axes[1])
        
        plt.tight_layout()
        st.pyplot(fig)
        
        # Dendrograma
        st.subheader("üå≥ Dendrograma")
        
        fig, ax = plt.subplots(figsize=(12, 6))
        linkage_matrix = linkage(X_scaled, method='average')
        dendrogram(linkage_matrix, ax=ax)
        ax.set_title('Dendrograma - Clustering Jer√°rquico (Average Linkage)')
        ax.set_xlabel('√çndice de Muestra')
        ax.set_ylabel('Distancia')
        st.pyplot(fig)
        
        # Distribuci√≥n de clusters
        st.subheader("üìä Distribuci√≥n de Clusters")
        cluster_counts = pd.Series(cluster_labels).value_counts().sort_index()
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            fig, ax = plt.subplots(figsize=(8, 4))
            cluster_counts.plot(kind='bar', ax=ax, color='steelblue')
            ax.set_xlabel('Cluster')
            ax.set_ylabel('N√∫mero de Muestras')
            ax.set_title('Muestras por Cluster')
            plt.xticks(rotation=0)
            st.pyplot(fig)
        
        with col2:
            st.markdown("**Conteo por Cluster:**")
            for cluster, count in cluster_counts.items():
                st.write(f"Cluster {cluster}: {count} muestras")

# ==================== ZONA DE EXPORTACI√ìN ====================
elif mode == "üíæ Zona de Exportaci√≥n":
    st.header("üíæ Zona de Exportaci√≥n (Dev Tools)")
    st.markdown("Descargue los modelos entrenados y sus resultados en formato JSON y PKL.")
    
    st.divider()
    
    # Exportaci√≥n Modelo Supervisado
    st.subheader("üìä Modelo Supervisado - AdaBoost")
    
    if 'supervised_model' in st.session_state:
        col1, col2 = st.columns(2)
        
        with col1:
            # JSON
            json_data = {
                "model_type": "Supervised",
                "model_name": "AdaBoost",
                "parameters": {
                    "n_estimators": st.session_state.get('supervised_model').n_estimators,
                    "learning_rate": st.session_state.get('supervised_model').learning_rate,
                    "algorithm": "SAMME"
                },
                "metrics": st.session_state['supervised_metrics'],
                "current_prediction": st.session_state.get('current_prediction', {})
            }
            
            json_str = json.dumps(json_data, indent=2)
            
            st.download_button(
                label="üì• Descargar JSON",
                data=json_str,
                file_name="adaboost_results.json",
                mime="application/json"
            )
        
        with col2:
            # PKL
            model_pkl = pickle.dumps(st.session_state['supervised_model'])
            
            st.download_button(
                label="üì• Descargar Modelo (.pkl)",
                data=model_pkl,
                file_name="adaboost_model.pkl",
                mime="application/octet-stream"
            )
        
        st.success("‚úÖ Modelo supervisado disponible para descarga")
        
        with st.expander("üëÅÔ∏è Preview del JSON"):
            st.json(json_data)
    else:
        st.warning("‚ö†Ô∏è Primero debe entrenar el modelo supervisado")
    
    st.divider()
    
    # Exportaci√≥n Modelo No Supervisado
    st.subheader("üîç Modelo No Supervisado - Clustering Jer√°rquico")
    
    if 'unsupervised_model' in st.session_state:
        col1, col2 = st.columns(2)
        
        with col1:
            # JSON
            json_data = {
                "model_type": "Unsupervised",
                "algorithm": "Hierarchical Clustering (Average Linkage)",
                "parameters": {
                    "n_clusters": st.session_state['n_clusters'],
                    "linkage": "average"
                },
                "metrics": st.session_state['unsupervised_metrics'],
                "cluster_labels": st.session_state['cluster_labels'].tolist()
            }
            
            json_str = json.dumps(json_data, indent=2)
            
            st.download_button(
                label="üì• Descargar JSON",
                data=json_str,
                file_name="hierarchical_clustering_results.json",
                mime="application/json"
            )
        
        with col2:
            # PKL
            model_pkl = pickle.dumps(st.session_state['unsupervised_model'])
            
            st.download_button(
                label="üì• Descargar Modelo (.pkl)",
                data=model_pkl,
                file_name="hierarchical_clustering_model.pkl",
                mime="application/octet-stream"
            )
        
        st.success("‚úÖ Modelo no supervisado disponible para descarga")
        
        with st.expander("üëÅÔ∏è Preview del JSON"):
            st.json(json_data)
    else:
        st.warning("‚ö†Ô∏è Primero debe aplicar el clustering")

# Footer
st.divider()
st.markdown("""
<div style='text-align: center; color: gray;'>
    <p>ü§ñ Aplicaci√≥n de Machine Learning | AdaBoost & Clustering Jer√°rquico</p>
    <p>Desarrollado con Streamlit üéà</p>
</div>
""", unsafe_allow_html=True)